#1、k-means聚类算法：不能自动识别类的个数,随即挑选初始点为中心点计算
（1）适当选择c个类的初始中心；
（2）在第k次迭代中，对任意一个样本，求其到c个中心的距离，将该样本归到距离最短的中心所在的类；
（3）利用均值等方法更新该类的中心值；
（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。
以上是KMeans（C均值）算法的具体步骤，可以看出需要选择类别数量，但初次选择是随机的，最终的聚类中心是不断迭代稳定以后的聚类中心。

#2、时间序列中常用预测技术  一个时间序列是一组对于某一变量连续时间点或连续时段上的观测值。
  1.  移动平均法 (MA)
  1.1. 简单移动平均法
  设有一时间序列y1,y2,..., 则按数据点的顺序逐点推移求出N个数的平均数，即可得到一次移动平均数.
   1.2 趋势移动平均法  
  当时间序列没有明显的趋势变动时，使用一次移动平均就能够准确地反映实际情况，直接用第t周期的一次移动平均数就可预测第1t+周期之值。
  时间序列出现线性变动趋势时，用一次移动平均数来预测就会出现滞后偏差。修正的方法是在一次移动平均的基础上再做二次移动平均，利用移动平均滞后偏差的规律找出曲线的发展方向和发展趋势，然后才建立直线趋势的预测模型。故称为趋势移动平均法。
  2.  自回归模型(AR)
  AR模型是一种线性预测，即已知N个数据，可由模型推出第N点前面或后面的数据（设推出P点）.
  本质类似于插值，其目的都是为了增加有效数据，只是AR模型是由N点递推，而插值是由两点（或少数几点）去推导多点，所以AR模型要比插值方法效果更好。
  3. 自回归滑动平均模型(ARMA)
  其建模思想可概括为：逐渐增加模型的阶数，拟合较高阶模型，直到再增加模型的阶数而剩余残差方差不再显著减小为止。
  4. GARCH模型
  回归模型。除去和普通回归模型相同的之处，GARCH对误差的方差进行了进一步的建模。特别适用于波动性的分析和预测。
  5. 指数平滑法
  移动平均法的预测值实质上是以前观测值的加权和，且对不同时期的数据给予相同的加权。这往往不符合实际情况。
  指数平滑法则对移动平均法进行了改进和发展，其应用较为广泛。
  基本思想都是：预测值是以前观测值的加权和，且对不同的数据给予不同的权，新数据给较大的权，旧数据给较小的权。
  根据平滑次数不同，指数平滑法分为：一次指数平滑法、二次指数平滑法和三次指数平滑法等。
  
  此外：
  相对强弱指数 (RSI, Relative Strength Index) 是通过比较一段时期内的平均收盘涨数
  和平均收盘跌数来分析市场买沽盘的意向和实力 , 从而作出未来市场的走势 .
  
  移动平均聚散指标 (MACD, Moving Average Convergence Divergence), 是根据均
  线的构造原理 , 对股票价格的收盘价进行平滑处理 , 求出算术平均值以后再进行计算 , 是
  一种趋向类指标 .
  
  随机指标 (KDJ) 一般是根据统计学的原理 , 通过一个特定的周期 ( 常为 9 日 ,9 周等 ) 内出
  现过的最高价 , 最低价及最后一个计算周期的收盘价及这三者之间的比例关系 , 来计算最
  后一个计算周期的未成熟随机值 RSV, 然后根据平滑移动平均线的方法来计算 K 值 , D 值
  与 J 值 , 并绘成曲线图来研判股票走势 .
  
#3、 众数、中位数、均值
  （1）当数据关于均值对称分布时，偏度为0；当右边的数据更分散时，为右偏，反之左偏。
  若众数小于中位数，左边更集中右边更分散
  
  （2）一组数据,均值>中位数>众数,这组数据则是右偏
  
#4、SQL
  （1）％：表示任意长度的字符串（长度可以为0）。
  （2）_	：仅替代一个字符
  （3）[charlist] ：字符列中的任何单一字符
  （4）[^charlist]或者[!charlist] ： 不在字符列中的任何单一字符
  
#5、正态分布
（1）偏度（Skewness）是描述某变量取值分布对称性的统计量。
如果是正太分布的话.偏度是 三阶中心距,值为0.
Skewness=0     分布形态与正态分布偏度相同
Skewness>0     正偏差数值较大，为正偏或右偏。长尾巴拖在右边。
Skewness<0     负偏差数值较大，为负偏或左偏。长尾巴拖在左边。
计算公式：
Skewness=E[((x-E(x))/(\sqrt{D(x)}))^3] 
| Skewness| 越大，分布形态偏移程度越大。

（2）峰度（Kurtosis）是描述某变量所有取值分布形态陡缓程度的统计量。
它是和正态分布相比较的。
Kurtosis=0       与正态分布的陡缓程度相同。
Kurtosis>0       比正态分布的高峰更加陡峭——尖顶峰
Kurtosis<0       比正态分布的高峰来得平台——平顶峰
计算公式：
Kurtosis=E[ ( (x-E(x))/ (\sqrt(D(x)))   )^4 ]-3   四阶中心距-3.

如果是正态分布,那么偏度,峰度均为0.

#6、模型的区别
AR模型：自回归模型，是一种线性模型
MA模型：移动平均法模型，其中使用趋势移动平均法建立直线趋势的预测模型
ARMA模型：自回归滑动平均模型，拟合较高阶模型
GARCH模型：广义回归模型，对误差的方差建模，适用于波动性的分析和预测

#7、excel
INDEX: 函数返回表格或区域中的值或值的引用 .

MATCH: 在范围单元格中搜索特定的项 , 然后返回该项在此区域中的相对位置 .

VLOOKUP&HLOOKUP: 在表格的首行或数值数组中搜索值 , 然后返回表格或数组中指定 行的所在列中的值 . 当比较值位于数据表格的首行时 , 如果要向下查看指定的行数 , 则可 使用 HLOOKUP; 当比较值位于所需查找的数据的左边一列时 , 则可使用 VLOOKUP.

FIND: 返回一个字符串在另一个字符串中出现的起始位置 ( 区分大小写 ).

IF: 可以对值和期待值进行逻辑比较 .

LIKE: 可用Like运算符自定义字符比较函数之类的, 应该是VBA的函数.

#8、信息熵和基尼系数
信息熵 Ent=- ∑ R_{ij}log R_{ij}, Ent 的值越小 , 则纯度越高 .
基尼系数 Gini=1- ∑ R_{ij}^2, Gini 越小 , 则纯度越高 .

#9、相关系数
（1）pearson相关系数
（2）Spearman秩相关系数

相关系数ρXY取值在-1到1之间，
ρXY = 0时，称X,Y不相关;
| ρXY | = 1时，称X,Y完全相关，此时，X,Y之间具有线性函数关系; 
| ρXY | < 1时，X的变动引起Y的部分变动，ρXY的绝对值越大，X的变动引起Y的变动就越大，
| ρXY | > 0.8时称为高度相关，当 | ρXY | < 0.3时称为低度相关，其它时候为中度相关。

#10、一元线性回归
一元线性回归的基本假设有
1、随机误差项是一个期望值或平均值为0的随机变量； 
2、对于解释变量的所有观测值，随机误差项有相同的方差； 
3、随机误差项彼此不相关；
4、解释变量是确定性变量，不是随机变量，与随机误差项彼此之间相互独立；
5、解释变量之间不存在精确的（完全的）线性关系，即解释变量的样本观测值矩阵是满秩矩阵；
6、随机误差项服从正态分布

违背基本假设的计量经济学模型还是可以估计的，只是不能使用普通最小二乘法进行估计。 
当存在异方差时，普通最小二乘法估计存在以下问题： 参数估计值虽然是无偏的，但不是最小方差线性无偏估计。

杜宾-瓦特森（DW）检验，计量经济，统计分析中常用的一种检验序列一阶 自相关 最常用的方法。 

所谓多重共线性（Multicollinearity）是指线性回归模型中的解释变量之间由于存在精确相关关系或高度相关关系而使模型估计失真或难以估计准确。影响
（1）完全共线性下参数估计量不存在
（2）近似共线性下OLS估计量非有效
多重共线性使参数估计值的方差增大，1/(1-r2)为方差膨胀因子(Variance Inflation Factor, VIF)
（3）参数估计量经济含义不合理
（4）变量的显著性检验失去意义，可能将重要的解释变量排除在模型之外
（5）模型的预测功能失效。变大的方差容易使区间预测的“区间”变大，使预测失去意义。

#11、高维数据进行降维的方法
LASSO
主成分分析法
小波分析法
线性判别法
拉普拉斯特征映射

#12、二叉树的遍历
二叉树的遍历有三种方式，如下：

（1）前序遍历（DLR），首先访问根结点，然后遍历左子树，最后遍历右子树。简记根-左-右。

（2）中序遍历（LDR），首先遍历左子树，然后访问根结点，最后遍历右子树。简记左-根-右。

（3）后序遍历（LRD），首先遍历左子树，然后遍历右子树，最后访问根结点。简记左-右-根。 

#13、构造函数
构造函数初始化时必须采用初始化列表一共有三种情况，   
1.需要初始化的数据成员是对象(继承时调用基类构造函数)   
2.需要初始化const修饰的类成员   
3.需要初始化引用成员数据

#14、HttpServletRequest
HttpServletRequest类主要处理：
1.读取和写入HTTP头标
2.取得和设置cookies
3.取得路径信息
4.标识HTTP会话

#15、在Java中定义String数组，有两种定义方式：String a[]和String[] a

  